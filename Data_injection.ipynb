{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11e4d7ac-1803-4650-a5d0-9c2cb6d8cf90",
   "metadata": {},
   "source": [
    "## Initial Attempts to Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acea02fe-a402-4a4f-b08f-c95625ae7bcb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m      4\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men-fr.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPandas read time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_time\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1919\u001b[0m     (\n\u001b[0;32m   1920\u001b[0m         index,\n\u001b[0;32m   1921\u001b[0m         columns,\n\u001b[0;32m   1922\u001b[0m         col_dict,\n\u001b[1;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mread(  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m         nrows\n\u001b[0;32m   1925\u001b[0m     )\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread_low_memory(nrows)\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2053\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m<frozen codecs>:319\u001b[0m, in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "df = pd.read_csv('en-fr.csv')\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Pandas read time: {end_time - start_time} seconds\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fbf33c70-85ec-48c3-a712-f0d0d1776e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dask read time: 0.014001607894897461 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Changing Lives | Changing Society | How It Wor...</td>\n",
       "      <td>Il a transformé notre vie | Il a transformé la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Site map</td>\n",
       "      <td>Plan du site</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Feedback</td>\n",
       "      <td>Rétroaction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Credits</td>\n",
       "      <td>Crédits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Français</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  en  \\\n",
       "0  Changing Lives | Changing Society | How It Wor...   \n",
       "1                                           Site map   \n",
       "2                                           Feedback   \n",
       "3                                            Credits   \n",
       "4                                           Français   \n",
       "\n",
       "                                                  fr  \n",
       "0  Il a transformé notre vie | Il a transformé la...  \n",
       "1                                       Plan du site  \n",
       "2                                        Rétroaction  \n",
       "3                                            Crédits  \n",
       "4                                            English  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "start_time = time.time()\n",
    "df = dd.read_csv('en-fr.csv')\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Dask read time: {end_time - start_time} seconds\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06d697f3-3ba4-45ac-bfaa-3f3bb307ce6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:44:09,502\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\ray\\session_2024-08-12_18-43-29_320858_2652\\logs\\ray-data\n",
      "2024-08-12 18:44:09,503\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadCSV]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ray read time: 0.008155107498168945 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45d8fc458ddc47dda88a8c9391a8e3e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ReadCSV->SplitBlocks(4) 1: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e451c052bc7248418b79d963b4c411ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Column  Type\n",
       "------  ----\n",
       "en      string\n",
       "fr      string"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "start_time = time.time()\n",
    "df = ray.data.read_csv('en-fr.csv')\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Ray read time: {end_time - start_time} seconds\")\n",
    "df.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "893115c8-80ae-4401-bd33-878e55dfb162",
   "metadata": {},
   "outputs": [
    {
     "ename": "RayTaskError(MemoryError)",
     "evalue": "\u001b[36mray::_deploy_ray_func()\u001b[39m (pid=6176, ip=127.0.0.1)\n  File \"python\\ray\\_raylet.pyx\", line 1858, in ray._raylet.execute_task\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\modin\\core\\execution\\ray\\common\\engine_wrapper.py\", line 53, in _deploy_ray_func\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\modin\\logging\\logger_decorator.py\", line 144, in run_and_log\n    return obj(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\modin\\core\\storage_formats\\pandas\\parsers.py\", line 362, in parse\n    return PandasParser.generic_parse(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\modin\\logging\\logger_decorator.py\", line 144, in run_and_log\n    return obj(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\modin\\core\\storage_formats\\pandas\\parsers.py\", line 222, in generic_parse\n    pandas_df = callback(BytesIO(to_read), **kwargs)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\modin\\logging\\logger_decorator.py\", line 144, in run_and_log\n    return obj(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\modin\\core\\storage_formats\\pandas\\parsers.py\", line 386, in read_callback\n    return pandas.read_csv(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1026, in read_csv\n    return _read(filepath_or_buffer, kwds)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 626, in _read\n    return parser.read(nrows)\n           ^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1923, in read\n    ) = self._engine.read(  # type: ignore[attr-defined]\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\", line 234, in read\n    chunks = self._reader.read_low_memory(nrows)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"parsers.pyx\", line 838, in pandas._libs.parsers.TextReader.read_low_memory\n  File \"parsers.pyx\", line 921, in pandas._libs.parsers.TextReader._read_rows\n  File \"parsers.pyx\", line 1066, in pandas._libs.parsers.TextReader._convert_column_data\n  File \"parsers.pyx\", line 1105, in pandas._libs.parsers.TextReader._convert_tokens\n  File \"parsers.pyx\", line 1272, in pandas._libs.parsers.TextReader._convert_with_dtype\n  File \"parsers.pyx\", line 1285, in pandas._libs.parsers.TextReader._string_convert\n  File \"parsers.pyx\", line 1514, in pandas._libs.parsers._string_box_utf8\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.00 MiB for an array with shape (262144,) and data type object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRayTaskError(MemoryError)\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmodin\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmodin\u001b[39;00m\n\u001b[0;32m      3\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m----> 4\u001b[0m df \u001b[38;5;241m=\u001b[39m modin\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men-fr.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPandas read time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_time\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\modin\\utils.py:591\u001b[0m, in \u001b[0;36mexpanduser_path_arg.<locals>.decorator.<locals>.wrapped\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    589\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(patharg, Path):\n\u001b[0;32m    590\u001b[0m         params\u001b[38;5;241m.\u001b[39marguments[argname] \u001b[38;5;241m=\u001b[39m patharg\u001b[38;5;241m.\u001b[39mexpanduser()\n\u001b[1;32m--> 591\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m    592\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\modin\\logging\\logger_decorator.py:144\u001b[0m, in \u001b[0;36menable_logging.<locals>.decorator.<locals>.run_and_log\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;124;03mCompute function with logging if Modin logging is enabled.\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;124;03mAny\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m LogMode\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    146\u001b[0m logger \u001b[38;5;241m=\u001b[39m get_logger()\n\u001b[0;32m    147\u001b[0m logger\u001b[38;5;241m.\u001b[39mlog(log_level, start_line)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\modin\\pandas\\io.py:226\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    224\u001b[0m _, _, _, f_locals \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetargvalues(inspect\u001b[38;5;241m.\u001b[39mcurrentframe())\n\u001b[0;32m    225\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m f_locals\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m _pd_read_csv_signature}\n\u001b[1;32m--> 226\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\modin\\pandas\\io.py:116\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodin\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexecution\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdispatching\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfactories\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdispatcher\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FactoryDispatcher\n\u001b[0;32m    115\u001b[0m squeeze \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqueeze\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 116\u001b[0m pd_obj \u001b[38;5;241m=\u001b[39m FactoryDispatcher\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    117\u001b[0m \u001b[38;5;66;03m# This happens when `read_csv` returns a TextFileReader object for iterating through\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pd_obj, TextFileReader):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\modin\\core\\execution\\dispatching\\factories\\dispatcher.py:207\u001b[0m, in \u001b[0;36mFactoryDispatcher.read_csv\u001b[1;34m(cls, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;129m@_inherit_docstrings\u001b[39m(factories\u001b[38;5;241m.\u001b[39mBaseFactory\u001b[38;5;241m.\u001b[39m_read_csv)\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_csv\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mget_factory()\u001b[38;5;241m.\u001b[39m_read_csv(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\modin\\core\\execution\\dispatching\\factories\\factories.py:267\u001b[0m, in \u001b[0;36mBaseFactory._read_csv\u001b[1;34m(cls, **kwargs)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[0;32m    261\u001b[0m     _doc_io_method_template,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    265\u001b[0m )\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_csv\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mio_cls\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\modin\\logging\\logger_decorator.py:144\u001b[0m, in \u001b[0;36menable_logging.<locals>.decorator.<locals>.run_and_log\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;124;03mCompute function with logging if Modin logging is enabled.\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;124;03mAny\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m LogMode\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    146\u001b[0m logger \u001b[38;5;241m=\u001b[39m get_logger()\n\u001b[0;32m    147\u001b[0m logger\u001b[38;5;241m.\u001b[39mlog(log_level, start_line)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\modin\\core\\io\\file_dispatcher.py:165\u001b[0m, in \u001b[0;36mFileDispatcher.read\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39msingle_worker_read(fname, \u001b[38;5;241m*\u001b[39margs, reason\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(err), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    164\u001b[0m \u001b[38;5;66;03m# TextFileReader can also be returned from `_read`.\u001b[39;00m\n\u001b[1;32m--> 165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m AsyncReadMode\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(query_compiler, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtypes\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;66;03m# at the moment it is not possible to use `wait_partitions` function;\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;66;03m# in a situation where the reading function is called in a row with the\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;66;03m# same parameters, `wait_partitions` considers that we have waited for\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;66;03m# the end of remote calculations, however, when trying to materialize the\u001b[39;00m\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;66;03m# received data, it is clear that the calculations have not yet ended.\u001b[39;00m\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;66;03m# for example, `test_io_exp.py::test_read_evaluated_dict` is failed because of that.\u001b[39;00m\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;66;03m# see #5944 for details\u001b[39;00m\n\u001b[0;32m    173\u001b[0m     _ \u001b[38;5;241m=\u001b[39m query_compiler\u001b[38;5;241m.\u001b[39mdtypes\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m query_compiler\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\modin\\core\\storage_formats\\pandas\\query_compiler.py:329\u001b[0m, in \u001b[0;36mPandasQueryCompiler.dtypes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdtypes\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pandas\u001b[38;5;241m.\u001b[39mSeries:\n\u001b[1;32m--> 329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modin_frame\u001b[38;5;241m.\u001b[39mdtypes\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\modin\\core\\dataframe\\pandas\\dataframe\\dataframe.py:424\u001b[0m, in \u001b[0;36mPandasDataframe.dtypes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;124;03mCompute the data types if they are not cached.\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;124;03m    A pandas Series containing the data types for this dataframe.\u001b[39;00m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_dtypes_cache:\n\u001b[1;32m--> 424\u001b[0m     dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtypes\u001b[38;5;241m.\u001b[39mget()\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    426\u001b[0m     dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtypes()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\modin\\core\\dataframe\\pandas\\metadata\\dtypes.py:924\u001b[0m, in \u001b[0;36mModinDtypes.get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_materialized:\n\u001b[0;32m    923\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value):\n\u001b[1;32m--> 924\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value()\n\u001b[0;32m    925\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    926\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m pandas\u001b[38;5;241m.\u001b[39mSeries([])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\modin\\core\\io\\text\\text_file_dispatcher.py:946\u001b[0m, in \u001b[0;36mTextFileDispatcher._get_new_qc.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    904\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    905\u001b[0m \u001b[38;5;124;03mGet new query compiler from data received from workers.\u001b[39;00m\n\u001b[0;32m    906\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;124;03m    New query compiler, created from `new_frame`.\u001b[39;00m\n\u001b[0;32m    935\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    936\u001b[0m partition_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_partition(\n\u001b[0;32m    937\u001b[0m     partition_ids, [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(index_ids), column_widths\n\u001b[0;32m    938\u001b[0m )\n\u001b[0;32m    940\u001b[0m new_frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mframe_cls(\n\u001b[0;32m    941\u001b[0m     partition_ids,\n\u001b[0;32m    942\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_define_index(index_ids, index_name),\n\u001b[0;32m    943\u001b[0m     column_names,\n\u001b[0;32m    944\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    945\u001b[0m     column_widths,\n\u001b[1;32m--> 946\u001b[0m     dtypes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mget_dtypes(dtypes_ids, column_names),\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m new_query_compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mquery_compiler_cls(new_frame)\n\u001b[0;32m    949\u001b[0m skipfooter \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipfooter\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\modin\\logging\\logger_decorator.py:144\u001b[0m, in \u001b[0;36menable_logging.<locals>.decorator.<locals>.run_and_log\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;124;03mCompute function with logging if Modin logging is enabled.\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;124;03mAny\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m LogMode\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    146\u001b[0m logger \u001b[38;5;241m=\u001b[39m get_logger()\n\u001b[0;32m    147\u001b[0m logger\u001b[38;5;241m.\u001b[39mlog(log_level, start_line)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\modin\\core\\storage_formats\\pandas\\parsers.py:257\u001b[0m, in \u001b[0;36mPandasParser.get_dtypes\u001b[1;34m(cls, dtypes_ids, columns)\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;66;03m# each element in `partitions_dtypes` is a Series, where column names are\u001b[39;00m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;66;03m# used as index and types of columns for different partitions are used as values\u001b[39;00m\n\u001b[1;32m--> 257\u001b[0m partitions_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mmaterialize(dtypes_ids)\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m([\u001b[38;5;28mlen\u001b[39m(dtype) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m dtype \u001b[38;5;129;01min\u001b[39;00m partitions_dtypes]):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\modin\\core\\execution\\ray\\common\\engine_wrapper.py:139\u001b[0m, in \u001b[0;36mRayWrapper.materialize\u001b[1;34m(cls, obj_id)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ray\u001b[38;5;241m.\u001b[39mget(obj_id) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj_id, ray\u001b[38;5;241m.\u001b[39mObjectRef) \u001b[38;5;28;01melse\u001b[39;00m obj_id\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(obj, ray\u001b[38;5;241m.\u001b[39mObjectRef) \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m obj_id):\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ray\u001b[38;5;241m.\u001b[39mget(obj_id)\n\u001b[0;32m    141\u001b[0m ids \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    142\u001b[0m result \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ray\\_private\\auto_init_hook.py:21\u001b[0m, in \u001b[0;36mwrap_auto_init.<locals>.auto_init_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mauto_init_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     20\u001b[0m     auto_init_ray()\n\u001b[1;32m---> 21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py:103\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[0;32m    102\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ray\\_private\\worker.py:2659\u001b[0m, in \u001b[0;36mget\u001b[1;34m(object_refs, timeout)\u001b[0m\n\u001b[0;32m   2653\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2654\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid type of object refs, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(object_refs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, is given. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2655\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject_refs\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must either be an ObjectRef or a list of ObjectRefs. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2656\u001b[0m     )\n\u001b[0;32m   2658\u001b[0m \u001b[38;5;66;03m# TODO(ujvl): Consider how to allow user to retrieve the ready objects.\u001b[39;00m\n\u001b[1;32m-> 2659\u001b[0m values, debugger_breakpoint \u001b[38;5;241m=\u001b[39m worker\u001b[38;5;241m.\u001b[39mget_objects(object_refs, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m   2660\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(values):\n\u001b[0;32m   2661\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, RayError):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ray\\_private\\worker.py:871\u001b[0m, in \u001b[0;36mWorker.get_objects\u001b[1;34m(self, object_refs, timeout, return_exceptions)\u001b[0m\n\u001b[0;32m    869\u001b[0m     global_worker\u001b[38;5;241m.\u001b[39mcore_worker\u001b[38;5;241m.\u001b[39mdump_object_store_memory_usage()\n\u001b[0;32m    870\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, RayTaskError):\n\u001b[1;32m--> 871\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mas_instanceof_cause()\n\u001b[0;32m    872\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\n",
      "\u001b[1;31mRayTaskError(MemoryError)\u001b[0m: \u001b[36mray::_deploy_ray_func()\u001b[39m (pid=6176, ip=127.0.0.1)\n  File \"python\\ray\\_raylet.pyx\", line 1858, in ray._raylet.execute_task\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\modin\\core\\execution\\ray\\common\\engine_wrapper.py\", line 53, in _deploy_ray_func\n    result = func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\modin\\logging\\logger_decorator.py\", line 144, in run_and_log\n    return obj(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\modin\\core\\storage_formats\\pandas\\parsers.py\", line 362, in parse\n    return PandasParser.generic_parse(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\modin\\logging\\logger_decorator.py\", line 144, in run_and_log\n    return obj(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\modin\\core\\storage_formats\\pandas\\parsers.py\", line 222, in generic_parse\n    pandas_df = callback(BytesIO(to_read), **kwargs)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\modin\\logging\\logger_decorator.py\", line 144, in run_and_log\n    return obj(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\modin\\core\\storage_formats\\pandas\\parsers.py\", line 386, in read_callback\n    return pandas.read_csv(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1026, in read_csv\n    return _read(filepath_or_buffer, kwds)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 626, in _read\n    return parser.read(nrows)\n           ^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1923, in read\n    ) = self._engine.read(  # type: ignore[attr-defined]\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\", line 234, in read\n    chunks = self._reader.read_low_memory(nrows)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"parsers.pyx\", line 838, in pandas._libs.parsers.TextReader.read_low_memory\n  File \"parsers.pyx\", line 921, in pandas._libs.parsers.TextReader._read_rows\n  File \"parsers.pyx\", line 1066, in pandas._libs.parsers.TextReader._convert_column_data\n  File \"parsers.pyx\", line 1105, in pandas._libs.parsers.TextReader._convert_tokens\n  File \"parsers.pyx\", line 1272, in pandas._libs.parsers.TextReader._convert_with_dtype\n  File \"parsers.pyx\", line 1285, in pandas._libs.parsers.TextReader._string_convert\n  File \"parsers.pyx\", line 1514, in pandas._libs.parsers._string_box_utf8\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.00 MiB for an array with shape (262144,) and data type object"
     ]
    }
   ],
   "source": [
    "import modin.pandas as modin\n",
    "\n",
    "start_time = time.time()\n",
    "df = modin.read_csv('en-fr.csv')\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Pandas read time: {end_time - start_time} seconds\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0af38e-d608-4c55-9538-cc8e575f3bf1",
   "metadata": {},
   "source": [
    "## Computational Efficientcy Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5342d932-dbe3-455e-a972-53f69a2f5dfb",
   "metadata": {},
   "source": [
    "Dask and Ray both performs fairly well, taking around 0.01 seconds to read the dataset. However, pandas and modin both run into the problem of not being able to allocate enough space for the dataset when running on my computer. The performance of Ray is slightly better, but we will proceed with Dask since Ray had some errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd41e65-9427-48c7-8360-059dca09aebb",
   "metadata": {},
   "source": [
    "## Perform Basic Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0c8cc67f-88ec-4356-8871-ed2cbff5f679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting utility.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile utility.py\n",
    "import logging\n",
    "import os\n",
    "import subprocess\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import datetime \n",
    "import gc\n",
    "import re\n",
    "\n",
    "\n",
    "################\n",
    "# File Reading #\n",
    "################\n",
    "\n",
    "def read_config_file(filepath):\n",
    "    with open(filepath, 'r') as stream:\n",
    "        try:\n",
    "            return yaml.safe_load(stream)\n",
    "        except yaml.YAMLError as exc:\n",
    "            logging.error(exc)\n",
    "\n",
    "def col_header_val(df,table_config):\n",
    "    '''\n",
    "    replace whitespaces in the column\n",
    "    and standardized column names\n",
    "    '''\n",
    "    df.columns = df.columns.str.lower()\n",
    "    df.columns = df.columns.str.replace(' ','_',regex=True)\n",
    "    df.columns = list(map(lambda x: x.strip('_'), list(df.columns)))\n",
    "    expected_col = list(map(lambda x: x.lower(),  table_config['columns']))\n",
    "    expected_col.sort()\n",
    "    df.columns =list(map(lambda x: x.lower(), list(df.columns)))\n",
    "    df = df[sorted(df.columns)]\n",
    "    if len(df.columns) == len(expected_col) and list(expected_col)  == list(df.columns):\n",
    "        print(\"column name and column length validation passed\")\n",
    "        return 1\n",
    "    else:\n",
    "        print(\"column name and column length validation failed\")\n",
    "        mismatched_columns_file = list(set(df.columns).difference(expected_col))\n",
    "        print(\"Following File columns are not in the YAML file\",mismatched_columns_file)\n",
    "        missing_YAML_file = list(set(expected_col).difference(df.columns))\n",
    "        print(\"Following YAML columns are not in the file uploaded\",missing_YAML_file)\n",
    "        logging.info(f'df columns: {df.columns}')\n",
    "        logging.info(f'expected columns: {expected_col}')\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "50ef4df3-4223-4217-a544-19e6fc5224f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting file.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile file.yaml\n",
    "file_type: csv\n",
    "dataset_name: English_French_Translation\n",
    "file_name: en-fr\n",
    "table_name: English_French_Translation\n",
    "inbound_delimiter: \",\"\n",
    "outbound_delimiter: \"|\"\n",
    "skip_leading_rows: 1\n",
    "columns: \n",
    "    - en\n",
    "    - fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bdd318f-aa06-4c0d-a6da-c1728d846f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utility as util\n",
    "config_data = util.read_config_file(\"file.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3836f84-bcbc-4976-9170-8e1618c75a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Changing Lives | Changing Society | How It Wor...</td>\n",
       "      <td>Il a transformé notre vie | Il a transformé la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Site map</td>\n",
       "      <td>Plan du site</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Feedback</td>\n",
       "      <td>Rétroaction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Credits</td>\n",
       "      <td>Crédits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Français</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  en  \\\n",
       "0  Changing Lives | Changing Society | How It Wor...   \n",
       "1                                           Site map   \n",
       "2                                           Feedback   \n",
       "3                                            Credits   \n",
       "4                                           Français   \n",
       "\n",
       "                                                  fr  \n",
       "0  Il a transformé notre vie | Il a transformé la...  \n",
       "1                                       Plan du site  \n",
       "2                                        Rétroaction  \n",
       "3                                            Crédits  \n",
       "4                                            English  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "# read the file using config file\n",
    "file_type = config_data['file_type']\n",
    "source_file = \"./\" + config_data['file_name'] + f'.{file_type}'\n",
    "#print(\"\",source_file)\n",
    "df = dd.read_csv(source_file)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "139fb675-ff87-42da-99da-4ab1dc52c34d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22520376"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6027bdd3-6847-4ad4-b678-d287e8313916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column name and column length validation passed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util.col_header_val(df,config_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b08e99-c8b3-414b-a5de-2c89c9dbe928",
   "metadata": {},
   "source": [
    "## Write the gz file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97378afc-129f-4e24-87e4-2bcb48719cc6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m compression_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m output_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m config_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtable_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 4\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(output_file, sep\u001b[38;5;241m=\u001b[39mconfig_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutbound_delimiter\u001b[39m\u001b[38;5;124m'\u001b[39m], compression\u001b[38;5;241m=\u001b[39mcompression_type, single_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\dask_expr\\_collection.py:2425\u001b[0m, in \u001b[0;36mFrameBase.to_csv\u001b[1;34m(self, filename, **kwargs)\u001b[0m\n\u001b[0;32m   2422\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"See dd.to_csv docstring for more information\"\"\"\u001b[39;00m\n\u001b[0;32m   2423\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask_expr\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcsv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_csv\n\u001b[1;32m-> 2425\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m to_csv(\u001b[38;5;28mself\u001b[39m, filename, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\dask_expr\\io\\csv.py:257\u001b[0m, in \u001b[0;36mto_csv\u001b[1;34m(df, filename, single_file, encoding, mode, name_function, compression, compute, scheduler, storage_options, header_first_partition_only, compute_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;124;03mStore Dask DataFrame to CSV files\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;124;03mfsspec.open_files\u001b[39;00m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcsv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_csv \u001b[38;5;28;01mas\u001b[39;00m _to_csv\n\u001b[1;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _to_csv(\n\u001b[0;32m    258\u001b[0m     df\u001b[38;5;241m.\u001b[39mto_legacy_dataframe(),\n\u001b[0;32m    259\u001b[0m     filename,\n\u001b[0;32m    260\u001b[0m     single_file\u001b[38;5;241m=\u001b[39msingle_file,\n\u001b[0;32m    261\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m    262\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m    263\u001b[0m     name_function\u001b[38;5;241m=\u001b[39mname_function,\n\u001b[0;32m    264\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m    265\u001b[0m     compute\u001b[38;5;241m=\u001b[39mcompute,\n\u001b[0;32m    266\u001b[0m     scheduler\u001b[38;5;241m=\u001b[39mscheduler,\n\u001b[0;32m    267\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    268\u001b[0m     header_first_partition_only\u001b[38;5;241m=\u001b[39mheader_first_partition_only,\n\u001b[0;32m    269\u001b[0m     compute_kwargs\u001b[38;5;241m=\u001b[39mcompute_kwargs,\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    271\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py:1005\u001b[0m, in \u001b[0;36mto_csv\u001b[1;34m(df, filename, single_file, encoding, mode, name_function, compression, compute, scheduler, storage_options, header_first_partition_only, compute_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m   1001\u001b[0m         compute_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscheduler\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m scheduler\n\u001b[0;32m   1003\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\n\u001b[1;32m-> 1005\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(dask\u001b[38;5;241m.\u001b[39mcompute(\u001b[38;5;241m*\u001b[39mvalues, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcompute_kwargs))\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1007\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\dask\\base.py:661\u001b[0m, in \u001b[0;36mcompute\u001b[1;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[0;32m    658\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[0;32m    660\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[1;32m--> 661\u001b[0m     results \u001b[38;5;241m=\u001b[39m schedule(dsk, keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    663\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\dask_expr\\_expr.py:3723\u001b[0m, in \u001b[0;36mFused._execute_task\u001b[1;34m(graph, name, *deps)\u001b[0m\n\u001b[0;32m   3721\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, dep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(deps):\n\u001b[0;32m   3722\u001b[0m     graph[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i)] \u001b[38;5;241m=\u001b[39m dep\n\u001b[1;32m-> 3723\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dask\u001b[38;5;241m.\u001b[39mcore\u001b[38;5;241m.\u001b[39mget(graph, name)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py:142\u001b[0m, in \u001b[0;36mCSVFunctionWrapper.__call__\u001b[1;34m(self, part)\u001b[0m\n\u001b[0;32m    139\u001b[0m         rest_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musecols\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m columns\n\u001b[0;32m    141\u001b[0m \u001b[38;5;66;03m# Call `pandas_read_text`\u001b[39;00m\n\u001b[1;32m--> 142\u001b[0m df \u001b[38;5;241m=\u001b[39m pandas_read_text(\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreader,\n\u001b[0;32m    144\u001b[0m     block,\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheader,\n\u001b[0;32m    146\u001b[0m     rest_kwargs,\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtypes,\n\u001b[0;32m    148\u001b[0m     columns,\n\u001b[0;32m    149\u001b[0m     write_header,\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menforce,\n\u001b[0;32m    151\u001b[0m     path_info,\n\u001b[0;32m    152\u001b[0m )\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m project_after_read:\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py:195\u001b[0m, in \u001b[0;36mpandas_read_text\u001b[1;34m(reader, b, header, kwargs, dtypes, columns, write_header, enforce, path)\u001b[0m\n\u001b[0;32m    193\u001b[0m bio\u001b[38;5;241m.\u001b[39mwrite(b)\n\u001b[0;32m    194\u001b[0m bio\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 195\u001b[0m df \u001b[38;5;241m=\u001b[39m reader(bio, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtypes:\n\u001b[0;32m    197\u001b[0m     coerce_dtypes(df, dtypes)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1919\u001b[0m     (\n\u001b[0;32m   1920\u001b[0m         index,\n\u001b[0;32m   1921\u001b[0m         columns,\n\u001b[0;32m   1922\u001b[0m         col_dict,\n\u001b[1;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mread(  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m         nrows\n\u001b[0;32m   1925\u001b[0m     )\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread_low_memory(nrows)\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2061\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: out of memory"
     ]
    }
   ],
   "source": [
    "file_type = 'gz'\n",
    "compression_type = 'gzip'\n",
    "output_file = \"./\" + config_data['table_name'] + f'.{file_type}'\n",
    "df.to_csv(output_file, sep=config_data['outbound_delimiter'], compression=compression_type, single_file=True)\n",
    "## Here my computer's RAM does not support running file of this size. It should work if we use a server or other processor with larger size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b614a67-8610-4ec9-9dad-715d52cc18d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
